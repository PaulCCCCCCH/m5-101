# 信息提取练习

## 1
每 3 秒钟向 http://icewould.com:5201/getProduct?id=1 发送请求，将获得的消息以如下格式打印出来：

```python
名字： Kobe的按摩椅
价格： 12415261$
店铺： Kobe代言的聚像
店铺主人： KobeNorris
商品参数： green 172cm 52kg
地址： 837 Zboncak Vista
```

注意观察并提取符合要求的 `key` 哦。

提示：使用 `requests.get("some_url").json()` 来获取 `json`，然后把它当作`字典`一样用就行。

## 2

前往 `http://www.nmc.cn/publish/marine/forecast.htm`。这个页面是官方的天气预报，每几个小时都会更新。  
<br>

请写一个脚本，每当运行时，会自动把这个页面的全部文字保存在 `weather.txt`  
<br>

## 3
请把上述网站的图片内容保存在 `img1.png`, `img2.png` ... `imgk.png`(假设一共有 `k` 张图片)。注意，你事先是不知道他一共有多少张图片的，每次更新，图片的数量都会不一样。  
<br>

这一步做完后，请把整个脚本打包成 `.exe`，双击运行后，会自动爬取文字和图片。  
<br>

## 4（挑战）
请前往 `https://movie.douban.com/top250` （豆瓣电影 Top 250），爬取全部的 250 部电影，并且统计，所有演职员的上榜次数，然后进行排名。  
<br>

提示 1：比如，要爬取[肖申克的救赎](https://movie.douban.com/subject/1292052/)的演职员，需要先电影列表页面对应标签的 `src` 获取链接，进入电影页面，用同样方法进入演职员表右上角的 `全部` 链接，然后更新统计数据。需要写一个循环，对每个电影都进行这个操作。  
<br>

提示 2：电影列表可以翻页，但是它们的 `url` 是有规律的。  
<br>

